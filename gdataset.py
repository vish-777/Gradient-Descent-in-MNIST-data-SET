# -*- coding: utf-8 -*-
"""GDAtaset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEQdm8FjmMg2Rd5CuxN4_1tuPOfiNpVp
"""

#gradient descent

#MNIST data SET
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix

from sklearn.datasets import load_digits
np.random.seed(seed=2020)

digits=load_digits()
print('we have %d samples'%len(digits.target))

fig=plt.figure(figsize=(8,8))
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
for i in range(32):
    ax=fig.add_subplot(8,8, i+1, xticks=[], yticks=[])
    ax.imshow(digits.images[i], cmap=plt.cm.gray_r)
    ax.text(0,1,str(digits.target[i]), bbox=dict(facecolor='white'))

X_train, X_test, Y_train, Y_test=train_test_split(digits.data, digits.target, test_size=0.2, random_state=2020)

print('Number of samples in training set: %d'%(len(Y_train)))
print('Number of samples in test set: %d'%(len(Y_test)))

scaler=StandardScaler()
scaler.fit(X_train)

X_train_scaled=scaler.transform(X_train)
X_test_scaled=scaler.transform(X_test)

mlp=MLPClassifier(hidden_layer_sizes=(100), activation='logistic', max_iter=100)

mlp.fit(X_train_scaled,Y_train)

print("Training set score: %f"%mlp.score(X_train_scaled, Y_train))
print("Test set score: %f"%mlp.score(X_test_scaled, Y_test))